{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Translation with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention is a technique that uses the output of our encoder: instead of discarding it entirely, we use it with our hidden state to pay attention to specific words in the input sentence for the predictions in the output sentence. Specifically, we compute attention weights, then add to the input of the decoder the linear combination of the output of the encoder, with those attention weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second things that might help is to use a bidirectional model for the encoder. We set the `bidrectional` parameter to `True` for our GRU encoder, and double the number of inputs to the linear output layer of the encoder.\n",
    "\n",
    "Also, we now need to set our hidden state:\n",
    "\n",
    "```\n",
    "hid = hid.view(2,self.n_layers, bs, self.n_hid).permute(1,2,0,3).contiguous()\n",
    "hid = self.out_enc(self.hid_dp(hid).view(self.n_layers, bs, 2*self.n_hid))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to re-run from start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.60\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "from fastai.text import *\n",
    "print(fastai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Config().data_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Config().data_path()/'giga-nah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_collate(samples:BatchSamples, pad_idx:int=1, pad_first:bool=True, backwards:bool=False) -> Tuple[LongTensor, LongTensor]:\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    samples = to_data(samples)\n",
    "    max_len_x,max_len_y = max([len(s[0]) for s in samples]),max([len(s[1]) for s in samples])\n",
    "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx\n",
    "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
    "    if backwards: pad_first = not pad_first\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            res_x[i,-len(s[0]):],res_y[i,-len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
    "        else:         \n",
    "            res_x[i,:len(s[0])],res_y[i,:len(s[1])] = LongTensor(s[0]),LongTensor(s[1])\n",
    "    if backwards: res_x,res_y = res_x.flip(1),res_y.flip(1)\n",
    "    return res_x,res_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataBunch(TextDataBunch):\n",
    "    \"Create a `TextDataBunch` suitable for training an RNN classifier.\"\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1,\n",
    "               dl_tfms=None, pad_first=False, device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:\n",
    "        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        collate_fn = partial(seq2seq_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTextList(TextList):\n",
    "    _bunch = Seq2SeqDataBunch\n",
    "    _label_cls = TextList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqDataBunch;\n",
       "\n",
       "Train: LabelList (26839 items)\n",
       "x: Seq2SeqTextList\n",
       "▁xxbos ▁toueue,▁xxbos ▁amo ▁ma ▁timoiljuikaj ▁kej ▁maseualmej ▁moiljuiaj,▁xxbos ▁ximomokuitlaui kaj,▁xxbos ▁para ▁axaka ▁inmech kajkayauas ▁ika ▁miak ▁tlajtoli ▁yejyektsitsij ▁uan ▁kej a ▁nopa ▁inmech ilpi s ▁ipan ▁tlen ▁axmelauak ▁uan ▁tlen ▁axipati,▁xxbos ▁uikatl\n",
       "y: TextList\n",
       "xxbos cónyuge,xxbos no pensamos como la gente piensa,xxbos cuidado,xxbos quizás haya alguien que se los lleve como presa suya mediante la filosofía y el vano engaño del mundo,xxbos canciones\n",
       "Path: /Users/ikhalil/.fastai/data/giga-nah;\n",
       "\n",
       "Valid: LabelList (6713 items)\n",
       "x: Seq2SeqTextList\n",
       "▁xxbos ▁kema ▁tlajtolmoyaua yaya ▁kinmatiltik ▁maseualmej ▁kenijkatsa ▁kintsontlamilti skiaj ▁katli ▁amo ▁kualmej,▁xxbos ▁¿ kenijkatsa ▁tijchijkej ▁tlaj ▁amo ▁tijpia yayaj ▁tomij ?,▁xxbos ▁uikatl ▁teotsij ▁mitsmokuitlauis,▁xxbos ▁ya ▁amo ▁moiljuik ▁tlaj ▁kiampa ▁ki nankiliskia ▁ya ▁kinankilik,▁xxbos ▁ikniuaj ▁katli ▁inmech tekimakatokej ▁xijchiuakaj ▁kej ▁ya\n",
       "y: TextList\n",
       "xxbos es obvio que el mensaje que predicó incluía la advertencia de que se acercaba una destrucción,xxbos ¿ y cómo nos las xxunk si casi no teníamos dinero ?,xxbos canción dios te cuidará,xxbos él no podía creer que el cura le respondiera de ese modo y le dijo,xxbos hermanos nombrados xxunk\n",
       "Path: /Users/ikhalil/.fastai/data/giga-nah;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data('/Volumes/iKhalil/NMT/RNN/JW/Sentence/nch/0.376264/', 'JW_Sentence_data.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Config().model_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nah -> esp\n",
    "emb_enc = torch.load(model_path/'nah_sentencex2_emb_JW.pth')\n",
    "emb_dec = torch.load(model_path/'es_sentencex2_emb_JW.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esp -> nah\n",
    "emb_enc = torch.load(model_path/'es_sentence_emb_JW_es.pth')\n",
    "emb_dec = torch.load(model_path/'nah_sentence_emb_JW_es.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(out, targ, pad_idx=1):\n",
    "    bs,targ_len = targ.size()\n",
    "    _,out_len,vs = out.size()\n",
    "    if targ_len>out_len: out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
    "    if out_len>targ_len: targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
    "    return CrossEntropyFlat()(out, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_acc(out, targ, pad_idx=1):\n",
    "    bs,targ_len = targ.size()\n",
    "    _,out_len,vs = out.size()\n",
    "    if targ_len>out_len: out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
    "    if out_len>targ_len: targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
    "    out = out.argmax(2)\n",
    "    return (out==targ).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGram():\n",
    "    def __init__(self, ngram, max_n=5000): self.ngram,self.max_n = ngram,max_n\n",
    "    def __eq__(self, other):\n",
    "        if len(self.ngram) != len(other.ngram): return False\n",
    "        return np.all(np.array(self.ngram) == np.array(other.ngram))\n",
    "    def __hash__(self): return int(sum([o * self.max_n**i for i,o in enumerate(self.ngram)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grams(x, n, max_n=5000):\n",
    "    return x if n==1 else [NGram(x[i:i+n], max_n=max_n) for i in range(len(x)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_ngrams(pred, targ, n, max_n=5000):\n",
    "    pred_grams,targ_grams = get_grams(pred, n, max_n=max_n),get_grams(targ, n, max_n=max_n)\n",
    "    pred_cnt,targ_cnt = Counter(pred_grams),Counter(targ_grams)\n",
    "    return sum([min(c, targ_cnt[g]) for g,c in pred_cnt.items()]),len(pred_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(learn, ds_type=DatasetType.Valid):\n",
    "    learn.model.eval()\n",
    "    inputs, targets, outputs = [],[],[]\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in progress_bar(learn.dl(ds_type)):\n",
    "            out = learn.model(xb)\n",
    "            for x,y,z in zip(xb,yb,out):\n",
    "                inputs.append(learn.data.train_ds.x.reconstruct(x))\n",
    "                targets.append(learn.data.train_ds.y.reconstruct(y))\n",
    "                outputs.append(learn.data.train_ds.y.reconstruct(z.argmax(1)))\n",
    "    return inputs, targets, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusBLEU(Callback):\n",
    "    def __init__(self, vocab_sz):\n",
    "        self.vocab_sz = vocab_sz\n",
    "        self.name = 'bleu'\n",
    "    \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.pred_len,self.targ_len,self.corrects,self.counts = 0,0,[0]*4,[0]*4\n",
    "    \n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        last_output = last_output.argmax(dim=-1)\n",
    "        for pred,targ in zip(last_output.cpu().numpy(),last_target.cpu().numpy()):\n",
    "            self.pred_len += len(pred)\n",
    "            self.targ_len += len(targ)\n",
    "            for i in range(4):\n",
    "                c,t = get_correct_ngrams(pred, targ, i+1, max_n=self.vocab_sz)\n",
    "                self.corrects[i] += c\n",
    "                self.counts[i]   += t\n",
    "    \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        precs = [c/t for c,t in zip(self.corrects,self.counts)]\n",
    "        len_penalty = exp(1 - self.targ_len/self.pred_len) if self.pred_len < self.targ_len else 1\n",
    "        bleu = len_penalty * ((precs[0]*precs[1]*precs[2]*precs[3]) ** 0.25)\n",
    "        return add_metrics(last_metrics, bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherForcing(LearnerCallback):\n",
    "    def __init__(self, learn, end_epoch):\n",
    "        super().__init__(learn)\n",
    "        self.end_epoch = end_epoch\n",
    "    \n",
    "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
    "        if train: return {'last_input': [last_input, last_target]}\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, **kwargs):\n",
    "        self.learn.model.pr_force = 1 - epoch/self.end_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidireccional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_attn(nn.Module):\n",
    "    def __init__(self, emb_enc, emb_dec, nh, out_sl, nl=2, bos_idx=0, pad_idx=1):\n",
    "        super().__init__()\n",
    "        self.nl,self.nh,self.out_sl,self.pr_force = nl,nh,out_sl,1\n",
    "        self.bos_idx,self.pad_idx = bos_idx,pad_idx\n",
    "        self.emb_enc,self.emb_dec = emb_enc,emb_dec\n",
    "        self.emb_sz_enc,self.emb_sz_dec = emb_enc.embedding_dim,emb_dec.embedding_dim\n",
    "        self.voc_sz_dec = emb_dec.num_embeddings\n",
    "                 \n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.gru_enc = nn.GRU(self.emb_sz_enc, nh, num_layers=nl, dropout=0.25, \n",
    "                              batch_first=True, bidirectional=True)\n",
    "        self.out_enc = nn.Linear(2*nh, self.emb_sz_dec, bias=False)\n",
    "        \n",
    "        self.gru_dec = nn.GRU(self.emb_sz_dec + 2*nh, self.emb_sz_dec, num_layers=nl,\n",
    "                              dropout=0.1, batch_first=True)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(self.emb_sz_dec, self.voc_sz_dec)\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "        self.enc_att = nn.Linear(2*nh, self.emb_sz_dec, bias=False)\n",
    "        self.hid_att = nn.Linear(self.emb_sz_dec, self.emb_sz_dec)\n",
    "        self.V =  self.init_param(self.emb_sz_dec)\n",
    "        \n",
    "    def encoder(self, bs, inp):\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, hid = self.gru_enc(emb, 2*h)\n",
    "        \n",
    "        pre_hid = hid.view(2, self.nl, bs, self.nh).permute(1,2,0,3).contiguous()\n",
    "        pre_hid = pre_hid.view(self.nl, bs, 2*self.nh)\n",
    "        hid = self.out_enc(pre_hid)\n",
    "        return hid,enc_out\n",
    "    \n",
    "    def decoder(self, dec_inp, hid, enc_att, enc_out):\n",
    "        hid_att = self.hid_att(hid[-1])\n",
    "        # we have put enc_out and hid through linear layers\n",
    "        u = torch.tanh(enc_att + hid_att[:,None])\n",
    "        # we want to learn the importance of each time step\n",
    "        attn_wgts = F.softmax(u @ self.V, 1)\n",
    "        # weighted average of enc_out (which is the output at every time step)\n",
    "        ctx = (attn_wgts[...,None] * enc_out).sum(1)\n",
    "        emb = self.emb_dec(dec_inp)\n",
    "        # concatenate decoder embedding with context (we could have just\n",
    "        # used the hidden state that came out of the decoder, if we weren't\n",
    "        # using attention)\n",
    "        outp, hid = self.gru_dec(torch.cat([emb, ctx], 1)[:,None], hid)\n",
    "        outp = self.out(self.out_drop(outp[:,0]))\n",
    "        return hid, outp\n",
    "        \n",
    "    def show(self, nm,v):\n",
    "        if False: print(f\"{nm}={v[nm].shape}\")\n",
    "        \n",
    "    def forward(self, inp, targ=None):\n",
    "        bs, sl = inp.size()\n",
    "        hid,enc_out = self.encoder(bs, inp)\n",
    "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
    "        enc_att = self.enc_att(enc_out)\n",
    "        \n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            hid, outp = self.decoder(dec_inp, hid, enc_att, enc_out)\n",
    "            res.append(outp)\n",
    "            dec_inp = outp.max(1)[1]\n",
    "            if (dec_inp==self.pad_idx).all(): break\n",
    "            if (targ is not None) and (random.random()<self.pr_force):\n",
    "                if i>=targ.shape[1]: continue\n",
    "                dec_inp = targ[:,i]\n",
    "        return torch.stack(res, dim=1)\n",
    "\n",
    "    def initHidden(self, bs): return one_param(self).new_zeros(2*self.nl, bs, self.nh)\n",
    "    def init_param(self, *sz): return nn.Parameter(torch.randn(sz)/math.sqrt(sz[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "hid=torch.Size([2, 64, 300])\n",
    "dec_inp=torch.Size([64])\n",
    "enc_att=torch.Size([64, 30, 300])\n",
    "hid_att=torch.Size([64, 300])\n",
    "u=torch.Size([64, 30, 300])\n",
    "attn_wgts=torch.Size([64, 30])\n",
    "enc_out=torch.Size([64, 30, 512])\n",
    "ctx=torch.Size([64, 512])\n",
    "emb=torch.Size([64, 300])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 100])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = next(iter(data.valid_dl))\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqRNN_attn(\n",
       "  (emb_enc): Embedding(1064, 300, padding_idx=1)\n",
       "  (emb_dec): Embedding(8000, 300, padding_idx=1)\n",
       "  (emb_enc_drop): Dropout(p=0.15, inplace=False)\n",
       "  (gru_enc): GRU(300, 256, num_layers=2, batch_first=True, dropout=0.25, bidirectional=True)\n",
       "  (out_enc): Linear(in_features=512, out_features=300, bias=False)\n",
       "  (gru_dec): GRU(812, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (out_drop): Dropout(p=0.35, inplace=False)\n",
       "  (out): Linear(in_features=300, out_features=8000, bias=True)\n",
       "  (enc_att): Linear(in_features=512, out_features=300, bias=False)\n",
       "  (hid_att): Linear(in_features=300, out_features=300, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Seq2SeqRNN_attn(emb_enc, emb_dec, 256, 100)\n",
    "learn = Learner(data, model, loss_func=seq2seq_loss, metrics=[seq2seq_acc, CorpusBLEU(len(data.y.vocab.itos))],\n",
    "                callback_fns=partial(TeacherForcing, end_epoch=30))\n",
    "model.train()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>seq2seq_acc</th>\n",
       "      <th>bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='78' class='' max='422', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      18.48% [78/422 10:58<48:24 18.7610]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 1.10E-02\n",
      "Min loss divided by 10: 1.32E-03\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(15, 3e-3)\n",
    "#learn.fit_one_cycle(10, 5.75E-02)#, div_factor=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>seq2seq_acc</th>\n",
       "      <th>bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.239378</td>\n",
       "      <td>5.615880</td>\n",
       "      <td>0.453116</td>\n",
       "      <td>0.375489</td>\n",
       "      <td>19:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train()\n",
    "learn.fit_one_cycle(1, 9.12E-04, div_factor=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='105' class='' max='105', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [105/105 00:48<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs, targets, outputs = get_predictions(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text ▁xxbos ▁¿ kenke ▁tlauel ▁moneki ▁timo echkapantlalisej ? ▁pampa ▁kej ▁kiijtok ▁ya ▁kiampa ▁tijyolpakiltiaj ▁toteotsij ▁nopa ▁amochtli ▁ ven ▁ s é ▁mi ▁ s eguido r ▁kiijtoua ▁kema ▁se ▁maseuali ▁tlauel ▁moueyimati ▁eli ▁kej uak ▁kipixto skia ▁se ▁tlamantli ▁tlen ▁tlauel ▁kitlanaui a ▁pampa ▁moueyimati ▁toteotsij ▁amo ▁kitekiuia ▁yon ▁se ▁kentsi ▁ maske ▁ueli ▁kichiua ▁miak ▁tlamantli ▁uan ▁kema ▁se ▁maseuali ▁moechkapantlali a ▁toteotsij ▁tlauel ▁kitekiuia ▁ maske ▁nopa ▁maseuali ▁nesi ▁amo ▁tleno ▁ipati ▁uan ▁nojkia ▁kiijtoua ▁toteotsij ▁tlauel ▁techteochiuas ▁tlaj ▁nojkia ▁tijnextisej ▁nopa ▁kuali ▁tlamantli ▁nochi ▁tojuantij ▁tijmatij ▁tlauel ▁ipati ▁ tijyolpakiltisej ▁toteotsij ▁toteotsij,\n",
       " Text xxbos la razón más importante para tener humildad es que eso agrada a dios como dejó claro él con relación a estas palabras el libro ven sé mi seguidor dice el orgullo es un veneno sumamente xxunk este defecto hace que hasta la persona más capaz sea xxunk para dios la humildad por otro lado convierte en instrumento útil para dios hasta a la persona más insignificante y añade que nuestro dios con gusto nos recompensará a nosotros si también manifestamos esa cualidad seguro que estamos de acuerdo en que no hay nada mejor que alegrar el corazón de dios,\n",
       " Text xxbos ¿ por qué es tan importante que xxunk como el escritor del libro ? él dice que los xxunk son xxunk si los xxunk somos una persona de buena gana la gratitud es un dios muy valioso para que la persona un regalo tan poderoso que no podemos tener un amor sincero)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[10], targets[10], outputs[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text ▁xxbos ▁uajka ▁tlaj ▁eli ▁san ▁se ▁istlakatili ▁kema ▁kiijtouaj ▁tijpiaj ▁se ▁alma ▁tlen ▁noju a ▁yoltok ▁kema ▁timikij ▁¿ tlake ▁techpano ▁kema ▁timikij ?,\n",
       " Text xxbos entonces si la enseñanza sobre la inmortalidad del alma se basa en una mentira ¿ qué sucede al morir ?,\n",
       " Text xxbos ahora bien si es cierto que la muerte es un enemigo que xxunk la muerte ¿ qué hace cuando alguien nos xxunk ?)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[909], targets[909], outputs[909]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text ▁xxbos ▁tetajmej ▁moneki ▁kim a jtosej ▁kej ▁kitlalnamikti sej ▁ininkone ▁uelis ▁kichiuas ▁noju a ▁ma ▁kitekipano ▁teotsij ▁o ▁ma ▁kitlauelkaua,\n",
       " Text xxbos los padres deben darse cuenta de que su reacción puede influir en si su hijo seguirá sirviendo a dios o no,\n",
       " Text xxbos los padres deben tener la mente de que sus hijos se xxunk de que dios sea su propio tiempo)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[1500], targets[1500], outputs[1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.eval();\n",
    "learn.export('JW_Sentence.pkl')\n",
    "learn.save('JW_Sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToTensor(phrase):\n",
    "    arrayT = []\n",
    "    arrayT.append(data.x.vocab.stoi[\"xxbos\"])\n",
    "    for word in phrase.split():\n",
    "        token = data.x.vocab.stoi[word]\n",
    "        arrayT.append(token)\n",
    "    return torch.tensor([arrayT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['in se xxunk las comidas sólo se usan una o dos ramitas',\n",
       " 'respuesta con que la hija así contesta a su madre y le agradece su plática su enseñanza',\n",
       " 'esta cilcuetzin matlaltzin se casó en tecuanipan pues la tomó por mujer tziuhtecatzin tzompahuacateuctli tlatohuani de tzompahuacan allá en tecuanipan dejó descendencia esta matlaltzin según lo refiere una tradición o xxunk de los chichimecas tenancas',\n",
       " 'es frío',\n",
       " 'ayocuantzin chichimecateuctli y cohuazacatzin teohuateuctli tlatoque de amaquemecan huyeron a huexotzinco cuauhtlehuanitzin tlailotlacteuctli y popocatzin atlauhtecatlteuctli tlatoque de tenanco también huyeron a huexotzinco quetzaltototzin tlatohuani de tecuanipan huyó a huexotzinco y asimismo teuctlacozauhcatzin tlamaocatlteuctli tlatohuani de panohuayan']"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paht = \"/Volumes/iKhalil 64G/NMT/RNN/Axolotl/Spacy/spa/0.322177/\"\n",
    "data = load_data(paht, 'Axolotl_Spaicy_es_data.pkl')\n",
    "learn = load_learner(paht,'Axolotl_Spaicy_es.pkl')\n",
    "learn.model.eval();\n",
    "sentences = []\n",
    "for s in data.valid_ds:\n",
    "    txt = s[0].text\n",
    "    txt = txt.replace('xxbos ', '')\n",
    "    sentences.append(txt)\n",
    "sentences[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences = list()\n",
    "\n",
    "i = 0\n",
    "for sentence in sentences:\n",
    "    test = learn.model(convertToTensor(sentence.lower()))\n",
    "    outputs = []\n",
    "    for z in zip(test):\n",
    "        outputs.append(\n",
    "            learn.data.train_ds.y.reconstruct(\n",
    "                z[0].argmax(1)\n",
    "            )\n",
    "        )\n",
    "    new_sentences.append(outputs)\n",
    "    if i < 5:\n",
    "        print(outputs)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['se se se xxunk xxunk se xxunk',\n",
       " 'tlananquililiztli in ic ic quinanquilia in tlahtohuani in oquitlapalo',\n",
       " 'ynin tlacatl yn ompa yn ompa tlacatl yn ompa yn yn ompa yn yn ompa yn chichimeca yn chichimeca yn ompa yn yn ompa quahuitzatzin yn ompa yn yn cihuapilli yn ompa yn yn atenco yn ipan yn ipan xihuitl yn ipan xihuitl',\n",
       " 'in sesek',\n",
       " 'yn çano yn itepeual yn huexotzinco ytoca quauhcececuitzin ytoca itoca uan huexotzinco ytoca itoca uan huexotzinco uan panohuayan ytoca tlatoani hualyetia michhuacan yn panohuayan ytoca chalco yn itoca ytoca ytzcahuacan yn mexica']"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_s = []\n",
    "for ss in new_sentences:\n",
    "    txt = ss[0].text\n",
    "    txt = txt.replace('xxbos ', '')\n",
    "    target_s.append(txt)\n",
    "target_s[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
